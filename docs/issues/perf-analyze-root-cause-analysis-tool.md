# [0.4] perf_analyze - åŸå› ç‰¹å®šãƒ„ãƒ¼ãƒ«

**Labels**: `backlog`, `target-0.4`, `performance`, `enhancement`, `priority-p2`  
**Milestone**: `v0.4.0`  
**Priority**: P2 (ä¾¡å€¤å‘ä¸Šå®Ÿè£…)

## ğŸ“‹ ç›®çš„
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å›å¸°ã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã€‚`perf_diff`ã§æ¤œå‡ºã•ã‚ŒãŸæ€§èƒ½å¤‰åŒ–ã®ã€Œãªãœã€ã‚’è§£æ˜ã—ã€é–‹ç™ºè€…ãŒè¿…é€Ÿã«å•é¡Œè§£æ±ºã§ãã‚‹è©³ç´°åˆ†æã‚’æä¾›ã™ã‚‹ã€‚

## ğŸ¯ å…·ä½“çš„ãªä»•æ§˜

### åŸºæœ¬CLIè¨­è¨ˆ
```bash
# åŸºæœ¬çš„ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ
python -m performance.tools.perf_analyze --profile cProfile --top 10
python -m performance.tools.perf_analyze --profile py-spy --duration 30s

# ç‰¹å®šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ·±æ˜ã‚Šåˆ†æ
python -m performance.tools.perf_analyze \
  --benchmark pattern_compilation \
  --profile cProfile \
  --compare-with v0.3.0 \
  --output analysis_report.md

# çµ±åˆåˆ†æ (diff + analyze)
python -m performance.tools.perf_analyze \
  --auto-detect-regression \
  --base-ref v0.3.0 \
  --head-ref HEAD \
  --profile py-spy \
  --duration 60s
```

### è©³ç´°ã‚³ãƒãƒ³ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³
```bash
# ãƒ•ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾‹
python -m performance.tools.perf_analyze \
  --benchmark rule_expansion \
  --profile cProfile \
  --sort-by cumulative \
  --top-functions 20 \
  --include-callgraph \
  --memory-profiling \
  --output-format json \
  --output analysis_detailed.json \
  --compare-baseline results/baseline_profile.json \
  --threshold-percent 10.0 \
  --verbose
```

## ğŸ”§ æŠ€è¡“ä»•æ§˜

### ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼

#### 1. cProfile (æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª)
```python
# å®Ÿè£…ä¾‹
import cProfile
import pstats
from io import StringIO

def run_cprofile_analysis(benchmark_func, sort_key='cumulative', top_n=20):
    """cProfileã«ã‚ˆã‚‹è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
    pr = cProfile.Profile()
    pr.enable()
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    result = benchmark_func()
    
    pr.disable()
    
    # çµ±è¨ˆæƒ…å ±ã®ç”Ÿæˆ
    s = StringIO()
    ps = pstats.Stats(pr, stream=s)
    ps.sort_stats(sort_key)
    ps.print_stats(top_n)
    
    return {
        'profile_data': s.getvalue(),
        'benchmark_result': result,
        'total_time': ps.total_tt,
        'function_stats': extract_function_stats(ps)
    }
```

#### 2. py-spy (ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼)
```python
import subprocess
import json
import tempfile

def run_pyspy_analysis(benchmark_command, duration_sec=30):
    """py-spyã«ã‚ˆã‚‹ä½ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
    with tempfile.NamedTemporaryFile(suffix='.json') as temp_file:
        # py-spyå®Ÿè¡Œ
        cmd = [
            'py-spy', 'record',
            '--pid', str(os.getpid()),
            '--duration', str(duration_sec),
            '--format', 'json',
            '--output', temp_file.name,
            '--'
        ] + benchmark_command.split()
        
        subprocess.run(cmd, check=True)
        
        # çµæœè§£æ
        with open(temp_file.name) as f:
            profile_data = json.load(f)
            
        return analyze_pyspy_output(profile_data)
```

#### 3. memory_profiler (ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡)
```python
from memory_profiler import profile, memory_usage

def run_memory_analysis(benchmark_func, interval=0.1):
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
    
    @profile
    def profiled_benchmark():
        return benchmark_func()
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
    mem_usage = memory_usage((profiled_benchmark, ()))
    
    return {
        'memory_usage': mem_usage,
        'peak_memory': max(mem_usage),
        'memory_delta': max(mem_usage) - min(mem_usage),
        'profile_output': get_line_profiler_output()
    }
```

### åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

#### Consoleå‡ºåŠ›å½¢å¼
```
ğŸ” Performance Analysis Report

ğŸ“Š Summary
  Benchmark: pattern_compilation
  Profiler: cProfile
  Total Time: 2.847s (1000 iterations)
  
ğŸ”¥ Top Bottlenecks (by cumulative time)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rank    â”‚ Function             â”‚ Calls    â”‚ Time     â”‚ Cumul    â”‚ Per Callâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1       â”‚ compile_patterns     â”‚ 1000     â”‚ 1.234s   â”‚ 1.234s   â”‚ 1.23ms  â”‚
â”‚ 2       â”‚ regex_optimization   â”‚ 5000     â”‚ 0.890s   â”‚ 2.124s   â”‚ 0.18ms  â”‚
â”‚ 3       â”‚ string_processing    â”‚ 15000    â”‚ 0.456s   â”‚ 0.456s   â”‚ 0.03ms  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸  Performance Concerns
  â€¢ compile_patterns: 43% of total time (expected ~20%)
  â€¢ regex_optimization: High call frequency (5x normal)
  â€¢ string_processing: Memory allocation inefficient

ğŸ”§ Optimization Suggestions
  1. Cache compiled regex patterns (estimated 30% improvement)
  2. Reduce regex_optimization calls via memoization
  3. Pre-allocate string buffers for processing

ğŸ“ˆ Historical Comparison (vs v0.3.0)
  compile_patterns: 0.890s â†’ 1.234s (+38.6% regression)  âš ï¸
  regex_optimization: 0.756s â†’ 0.890s (+17.7% regression)  âš ï¸
  string_processing: 0.445s â†’ 0.456s (+2.5% normal variance)  âœ…
```

#### JSONå‡ºåŠ›å½¢å¼
```json
{
  "metadata": {
    "timestamp": "2025-09-01T15:30:00Z",
    "benchmark": "pattern_compilation",
    "profiler": "cProfile",
    "total_time_seconds": 2.847,
    "iterations": 1000,
    "base_ref": "v0.3.0",
    "current_ref": "HEAD"
  },
  "top_functions": [
    {
      "rank": 1,
      "function_name": "compile_patterns",
      "module": "strataregula.core.compiler",
      "calls": 1000,
      "total_time": 1.234,
      "cumulative_time": 1.234,
      "per_call_ms": 1.23,
      "percentage_of_total": 43.4
    }
  ],
  "performance_issues": [
    {
      "severity": "high",
      "function": "compile_patterns",
      "issue": "Consuming 43% of total time (expected ~20%)",
      "suggestion": "Cache compiled regex patterns",
      "estimated_improvement": "30%"
    }
  ],
  "regression_analysis": [
    {
      "function": "compile_patterns",
      "base_time": 0.890,
      "current_time": 1.234,
      "change_percent": 38.6,
      "status": "regression",
      "significance": "high"
    }
  ],
  "optimization_suggestions": [
    {
      "priority": "high",
      "description": "Cache compiled regex patterns",
      "rationale": "Eliminates redundant compilation overhead",
      "estimated_impact": "30% performance improvement",
      "implementation_complexity": "medium"
    }
  ]
}
```

### perf_diffã¨ã®çµ±åˆ
```python
# performance/tools/perf_analyze.py
class PerformanceAnalyzer:
    def auto_analyze_regression(self, base_ref: str, current_ref: str):
        """å›å¸°è‡ªå‹•æ¤œå‡ºâ†’åŸå› åˆ†æ"""
        
        # 1. perf_diffå®Ÿè¡Œã§å›å¸°æ¤œå‡º
        diff_result = perf_diff.compare_commits(base_ref, current_ref)
        
        # 2. å›å¸°ã®ã‚ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç‰¹å®š
        regressions = [
            comp for comp in diff_result.comparisons 
            if comp.diff.status == "regression" and comp.diff.significance > 0.95
        ]
        
        # 3. å„å›å¸°ã«ã¤ã„ã¦è©³ç´°åˆ†æ
        analysis_results = []
        for regression in regressions:
            analysis = self.analyze_benchmark(
                benchmark=regression.benchmark,
                profiler="cProfile"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            )
            analysis_results.append(analysis)
        
        # 4. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        return self.generate_integrated_report(diff_result, analysis_results)
```

## ğŸ“Š æˆåŠŸæŒ‡æ¨™

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶
- **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰**: < 10% (py-spy: < 1%)
- **åˆ†æçµæœç”Ÿæˆæ™‚é–“**: < 5ç§’
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: < 100MB (ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿å«ã‚€)
- **ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé€Ÿåº¦**: < 1ç§’ (JSON/Markdown)

### æ©Ÿèƒ½è¦ä»¶
- âœ… 3ç¨®é¡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼å¯¾å¿œ (cProfile, py-spy, memory_profiler)
- âœ… å›å¸°åˆ†æçµ±åˆ (`perf_diff`ã¨ã®é€£æº)
- âœ… æœ€é©åŒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ 
- âœ… è¤‡æ•°å‡ºåŠ›å½¢å¼ (Console/JSON/Markdown)
- âœ… Historical comparison (baselineå¯¾æ¯”)

### ç²¾åº¦è¦ä»¶
- âœ… Bottleneckç‰¹å®šç²¾åº¦ > 95%
- âœ… æœ€é©åŒ–ææ¡ˆã®æœ‰åŠ¹æ€§ > 80%
- âœ… False positive rate < 5%
- âœ… çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼çµ„ã¿è¾¼ã¿

## ğŸ”§ å®Ÿè£…è©³ç´°

### ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼çµ±åˆã‚¯ãƒ©ã‚¹
```python
# performance/profilers/base.py
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, List, Any

@dataclass
class ProfileResult:
    profiler_type: str
    total_time: float
    function_stats: List[Dict]
    bottlenecks: List[Dict]
    suggestions: List[Dict]
    raw_data: Any

class ProfilerInterface(ABC):
    @abstractmethod
    def profile_benchmark(self, benchmark_func, **kwargs) -> ProfileResult:
        pass
    
    @abstractmethod
    def analyze_results(self, profile_data) -> Dict[str, Any]:
        pass

class CProfileProfiler(ProfilerInterface):
    def profile_benchmark(self, benchmark_func, **kwargs):
        # cProfileå®Ÿè£…
        pass

class PySpyProfiler(ProfilerInterface):  
    def profile_benchmark(self, benchmark_func, **kwargs):
        # py-spyå®Ÿè£…
        pass

class MemoryProfiler(ProfilerInterface):
    def profile_benchmark(self, benchmark_func, **kwargs):
        # memory_profilerå®Ÿè£…
        pass
```

### æœ€é©åŒ–ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³
```python
# performance/analysis/optimizer.py
class OptimizationEngine:
    def __init__(self):
        self.suggestion_rules = self.load_suggestion_rules()
    
    def analyze_bottlenecks(self, profile_result: ProfileResult) -> List[Dict]:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æâ†’æœ€é©åŒ–ææ¡ˆç”Ÿæˆ"""
        suggestions = []
        
        for func_stat in profile_result.function_stats:
            # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ææ¡ˆ
            for rule in self.suggestion_rules:
                if rule.matches(func_stat):
                    suggestion = rule.generate_suggestion(func_stat)
                    suggestions.append(suggestion)
        
        return self.prioritize_suggestions(suggestions)
    
    def load_suggestion_rules(self):
        """æœ€é©åŒ–ãƒ«ãƒ¼ãƒ«å®šç¾©"""
        return [
            RegexCompilationRule(),
            MemoryAllocationRule(), 
            LoopOptimizationRule(),
            CachingOpportunityRule(),
            StringProcessingRule()
        ]

class RegexCompilationRule:
    def matches(self, func_stat):
        return (
            "compile" in func_stat["function_name"].lower() and
            func_stat["calls"] > 100 and
            func_stat["per_call_time"] > 0.001  # 1ms
        )
    
    def generate_suggestion(self, func_stat):
        return {
            "priority": "high",
            "description": "Cache compiled regex patterns",
            "rationale": f"Function called {func_stat['calls']} times, each taking {func_stat['per_call_time']:.3f}ms",
            "estimated_impact": "20-40% improvement",
            "implementation": "Use @lru_cache decorator or class-level pattern storage"
        }
```

## ğŸ”„ ä½¿ç”¨ä¾‹ãƒ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### é–‹ç™ºè€…ã®å•é¡Œè§£æ±ºãƒ•ãƒ­ãƒ¼
```bash
# 1. æ€§èƒ½å›å¸°æ¤œå‡º (perf_diff)
python -m performance.tools.perf_diff --base v0.3.0 --head HEAD
# â†’ pattern_compilation ã§ 38% åŠ£åŒ–ã‚’æ¤œå‡º

# 2. åŸå› åˆ†æé–‹å§‹
python -m performance.tools.perf_analyze \
  --benchmark pattern_compilation \
  --profile cProfile \
  --compare-with v0.3.0

# 3. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚‚ç¢ºèª
python -m performance.tools.perf_analyze \
  --benchmark pattern_compilation \
  --profile memory_profiler \
  --include-line-by-line

# 4. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ (PRç”¨)
python -m performance.tools.perf_analyze \
  --auto-detect-regression \
  --base-ref v0.3.0 \
  --format markdown \
  --output regression_analysis.md
```

### CIçµ±åˆã§ã®è‡ªå‹•åˆ†æ
```yaml
# .github/workflows/performance-analysis.yml
- name: Detect Performance Regression
  run: |
    python -m performance.tools.perf_diff \
      --base ${{ github.event.pull_request.base.sha }} \
      --head ${{ github.sha }} \
      --output diff_report.json

- name: Auto-Analyze Regressions
  if: contains(fromJSON(steps.diff.outputs.result).summary.regressions, '> 0')
  run: |
    python -m performance.tools.perf_analyze \
      --auto-detect-regression \
      --base-ref ${{ github.event.pull_request.base.sha }} \
      --head-ref ${{ github.sha }} \
      --output analysis_report.md
      
- name: Comment Detailed Analysis
  uses: actions/github-script@v6
  with:
    script: |
      const fs = require('fs');
      const analysis = fs.readFileSync('analysis_report.md', 'utf8');
      
      github.rest.issues.createComment({
        issue_number: context.issue.number,
        owner: context.repo.owner,
        repo: context.repo.repo,
        body: `## ğŸ” Performance Regression Analysis\n\n${analysis}`
      });
```

## ğŸš« éç›®æ¨™ãƒ»åˆ¶é™äº‹é …

### ç¾åœ¨ã®ã‚¹ã‚³ãƒ¼ãƒ—å¤–
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°**: ãƒãƒƒãƒå®Ÿè¡Œã®ã¿
- **æœ¬ç•ªç’°å¢ƒå¯¾å¿œ**: é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç’°å¢ƒå°‚ç”¨
- **ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹å¯¾å¿œ**: ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã®ã¿
- **GUIå¯è¦–åŒ–**: CLI/ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹å‡ºåŠ›
- **è‡ªå‹•æœ€é©åŒ–**: ææ¡ˆç”Ÿæˆã®ã¿ã€å®Ÿè£…ã¯æ‰‹å‹•

### åˆ¶é™äº‹é …
- **py-spyä¾å­˜**: py-spyã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦
- **æ¨©é™è¦ä»¶**: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ¨©é™ãŒå¿…è¦ãªå ´åˆ
- **ãƒ¡ãƒ¢ãƒªåˆ¶ç´„**: å¤§è¦æ¨¡ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®åˆ¶é™
- **Pythoné™å®š**: Python codeãƒ™ãƒ¼ã‚¹ã®ã¿å¯¾å¿œ

## ğŸ”— é–¢é€£ãƒ»ä¾å­˜ Issues

### å‰ææ¡ä»¶
- âœ… Performance Tools MVP (0.3.0) - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åŸºç›¤
- â³ **perf_diff** (P1) - å›å¸°æ¤œå‡ºæ©Ÿèƒ½ã¨ã®çµ±åˆ
- âœ… JSONå‡ºåŠ›æ¨™æº–åŒ– - çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

### é€£æºå¼·åŒ–
- **perf_diff** (P1) - è‡ªå‹•å›å¸°åˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **CIå®Œå…¨çµ±åˆ** (P0) - è‡ªå‹•åˆ†æãƒˆãƒªã‚¬ãƒ¼
- **Performance ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** (P2) - æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰çµ±åˆ

### å¾Œç¶šå±•é–‹
- **perf_optimize** (0.5.0) - è‡ªå‹•æœ€é©åŒ–é©ç”¨
- **Performance Dashboard** (0.5.0) - Web UIå¯è¦–åŒ–
- **Historical Analysis** (0.5.0) - é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ

## âœ… å®Œäº†æ¡ä»¶ (Definition of Done)

### æŠ€è¡“è¦ä»¶
- [ ] 3ç¨®é¡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼çµ±åˆå‹•ä½œç¢ºèª
- [ ] è‡ªå‹•å›å¸°åˆ†ææ©Ÿèƒ½ (`--auto-detect-regression`) å‹•ä½œ
- [ ] æœ€é©åŒ–ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³ç²¾åº¦æ¤œè¨¼
- [ ] è¤‡æ•°å‡ºåŠ›å½¢å¼å“è³ªç¢ºèª
- [ ] perf_diffçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†

### å“è³ªè¦ä»¶
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆ Coverage > 85%
- [ ] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ç²¾åº¦æ¤œè¨¼
- [ ] æœ€é©åŒ–ææ¡ˆæœ‰åŠ¹æ€§ãƒ†ã‚¹ãƒˆ (å®Ÿéš›ã®æ”¹å–„ç¢ºèª)
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æ¸¬å®š

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ä»¶
- [ ] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼æ¯”è¼ƒãƒ»é¸æŠã‚¬ã‚¤ãƒ‰
- [ ] æœ€é©åŒ–ææ¡ˆå®Ÿè£…ä¾‹é›†
- [ ] ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ‰‹é †
- [ ] CIçµ±åˆè¨­å®šæ‰‹é †

### æ¤œè¨¼è¦ä»¶
- [ ] æ—¢çŸ¥ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡ºç¢ºèª
- [ ] å›å¸°åŸå› ç‰¹å®šç²¾åº¦æ¸¬å®š
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ (é–‹ç™ºè€…feedback)
- [ ] å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã®å‹•ä½œç¢ºèª

---

**æ¨å®šå·¥æ•°**: 3-4 weeks  
**æ‹…å½“è€…**: Performance Engineering Team  
**ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼**: Core Development + Performance Experts  
**ä½œæˆæ—¥**: 2025-09-01  
**æœ€çµ‚æ›´æ–°**: 2025-09-01