# ç¾ä»£çš„ãƒãƒƒã‚·ãƒ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆï¼šãƒ¬ã‚¬ã‚·ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¾¹åº•æ‰¹åˆ¤

## ğŸ”¥ å¾“æ¥è¨­è¨ˆã®è‡´å‘½çš„æ¬ é™¥åˆ†æ

### å•é¡Œã®æœ¬è³ªï¼š2000å¹´ä»£ã®Javaã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºè‡­

æ—¢å­˜ã®ãƒãƒƒã‚·ãƒ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­è¨ˆææ¡ˆã¯ã€**Enterprise Java 2005å¹´ãƒ¬ãƒ™ãƒ«**ã®æ™‚ä»£é…ã‚Œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚ç¾ä»£çš„ãªè¦³ç‚¹ã‹ã‚‰å®¹èµ¦ãªãæŒ‡æ‘˜ã™ã‚‹ã€‚

## ğŸ’€ ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å•é¡Œç‚¹

### 1. **Factory Pattern ã¯å®Œå…¨ã«ã‚ªãƒ¯ã‚³ãƒ³**

```python
# âŒ 20å¹´å‰ã® Java EEè„³
class HashFactory:
    def createCryptographic(self, algo: str): pass
    def createHighSpeed(self, algo: str): pass
```

```rust
// âœ… ç¾ä»£çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: é–¢æ•°å‹ + å‹å®‰å…¨æ€§
type HashFn<T> = fn(&[u8]) -> Result<Hash<T>, HashError>;

const BLAKE2B: HashFn<32> = |data| Blake2b::digest(data);
const XXHASH: HashFn<8> = |data| XxHash64::digest(data);

// é«˜éšé–¢æ•°ã§ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³
fn with_validation<const N: usize>(hasher: HashFn<N>) -> HashFn<N> {
    |data| hasher(data).and_then(validate_output)
}
```

**å•é¡Œç‚¹**ï¼š
- å®Ÿè¡Œæ™‚å‹ãƒã‚§ãƒƒã‚¯
- ç„¡é§„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
- ãƒ†ã‚¹ãƒˆã—ã«ãã„ä¾å­˜é–¢ä¿‚
- ãƒœã‚¤ãƒ©ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰å¤§é‡

### 2. **OOPè„³ã«ã‚ˆã‚‹éåº¦ãªã‚¯ãƒ©ã‚¹è¨­è¨ˆ**

```python
# âŒ ç„¡é§„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘
class HashContext:
    def __init__(self): pass
    def setStrategy(self): pass
    def hash(self): pass
```

```typescript
// âœ… é–¢æ•°å‹ + å‹å®‰å…¨æ€§
type HashAlgorithm = 'blake2b' | 'xxhash' | 'sha256';
type HashConfig<T extends HashAlgorithm> = {
  algorithm: T;
  key?: Uint8Array;
  parallel?: boolean;
};

const hash = <T extends HashAlgorithm>(
  data: Uint8Array, 
  config: HashConfig<T>
): Promise<Uint8Array> => {
  return algorithms[config.algorithm](data, config);
};
```

**å•é¡Œç‚¹**ï¼š
- çŠ¶æ…‹ç®¡ç†ã®è¤‡é›‘åŒ–
- ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
- ä¸¦è¡Œæ€§ã®é˜»å®³
- ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã®å›°é›£

### 3. **Plugin Registry = ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³**

```python
# âŒ å®Ÿè¡Œæ™‚å‹ãƒã‚§ãƒƒã‚¯åœ°ç„
class HashPluginRegistry:
    def register(self, plugin): pass  # anyå‹ã®æ‚ªå¤¢
```

```rust
// âœ… ãƒˆãƒ¬ã‚¤ãƒˆãƒ™ãƒ¼ã‚¹ + ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–
trait Hasher {
    const OUTPUT_SIZE: usize;
    type Output: AsRef<[u8]>;
    
    fn hash(&self, data: &[u8]) -> Self::Output;
}

// ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«å…¨ã¦è§£æ±º
fn hash_with<H: Hasher>(hasher: H, data: &[u8]) -> H::Output {
    hasher.hash(data)
}
```

**å•é¡Œç‚¹**ï¼š
- å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã®æ¸©åºŠ
- å‹å®‰å…¨æ€§ã®æ¬ å¦‚
- å‹•çš„ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æ€§èƒ½åŠ£åŒ–
- ãƒ‡ãƒãƒƒã‚°ã®å›°é›£

### 4. **éåŒæœŸå‡¦ç†ã®å®Œå…¨ç„¡è¦–**

```python
# âŒ åŒæœŸå‡¦ç†ã®ã¿ = 2010å¹´ä»£æ€è€ƒ
def hash(data: bytes) -> bytes: pass
```

```javascript
// âœ… ç¾ä»£çš„éåŒæœŸ + Workeræ´»ç”¨
const hashParallel = async (
  data: Uint8Array,
  algorithm: HashAlgorithm,
  chunkSize = 1024 * 1024
): Promise<Uint8Array> => {
  const chunks = chunkArray(data, chunkSize);
  const workers = await Promise.all(
    chunks.map(chunk => 
      new Worker('/hash-worker.js').postMessage({algorithm, chunk})
    )
  );
  return combineHashes(workers);
};
```

**å•é¡Œç‚¹**ï¼š
- UIãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°
- CPUãƒªã‚½ãƒ¼ã‚¹ã®éåŠ¹ç‡åˆ©ç”¨
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®æ¬ å¦‚
- ç¾ä»£çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã®éäº’æ›

## ğŸš€ ç¾ä»£çš„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³

### **1. Functional Pipeline Architecture**

```rust
// é–¢æ•°åˆæˆã«ã‚ˆã‚‹ãƒãƒƒã‚·ãƒ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
use futures::stream::{Stream, StreamExt};

async fn hash_pipeline<S>(
    input: S
) -> Result<Hash, PipelineError>
where 
    S: Stream<Item = Bytes> + Send,
{
    input
        .chunks(CHUNK_SIZE)
        .map(|chunk| async move { 
            tokio::spawn(async move { hash_chunk(chunk).await })
        })
        .buffer_unordered(cpu_count())
        .try_fold(HashState::new(), |acc, hash| {
            async move { Ok(acc.combine(hash)) }
        })
        .await
}
```

**åˆ©ç‚¹**ï¼š
- **ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³**: é–¢æ•°ã‚’çµ„ã¿åˆã‚ã›ã¦è¤‡é›‘ãªå‡¦ç†æ§‹ç¯‰
- **ä¸¦è¡Œæ€§**: è‡ªç„¶ãªä¸¦åˆ—å‡¦ç†
- **ãƒ†ã‚¹ãƒˆæ€§**: å„é–¢æ•°ãŒç‹¬ç«‹ã—ã¦ãƒ†ã‚¹ãƒˆå¯èƒ½
- **äºˆæ¸¬å¯èƒ½æ€§**: å‰¯ä½œç”¨ã®æ˜ç¢ºãªåˆ†é›¢

### **2. Type-Level Algorithm Selection**

```typescript
// å‹ãƒ¬ãƒ™ãƒ«ã§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç‰¹æ€§ã‚’ä¿è¨¼
interface CryptographicHash {
  readonly security: 'cryptographic';
  readonly outputSize: 32 | 64;
}

interface FastHash {
  readonly security: 'checksum';
  readonly outputSize: 4 | 8;
}

type HashFor<Purpose extends 'security' | 'speed'> = 
  Purpose extends 'security' ? CryptographicHash : FastHash;

const selectHash = <P extends 'security' | 'speed'>(
  purpose: P
): HashFor<P> => {
  // ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«å‹å®‰å…¨æ€§ä¿è¨¼
  return purpose === 'security' 
    ? { security: 'cryptographic', outputSize: 32 } as HashFor<P>
    : { security: 'checksum', outputSize: 8 } as HashFor<P>;
};
```

**åˆ©ç‚¹**ï¼š
- **ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ä¿è¨¼**: å®Ÿè¡Œå‰ã«ã‚¨ãƒ©ãƒ¼æ¤œå‡º
- **é›¶ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–**: å®Ÿè¡Œæ™‚ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã—
- **APIå®‰å…¨æ€§**: èª¤ã£ãŸçµ„ã¿åˆã‚ã›ã‚’é˜²æ­¢
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ€§**: å‹ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½

### **3. Reactive Hash Streaming**

```javascript
// RxJSé¢¨ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
import { from, combineLatest } from 'rxjs';
import { map, scan, shareReplay } from 'rxjs/operators';

const hashStream$ = (file$: Observable<File>) =>
  file$.pipe(
    // ä¸¦åˆ—ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
    switchMap(file => 
      from(file.stream().getReader()).pipe(
        map(({value}) => value),
        scan((hasher, chunk) => hasher.update(chunk), new Blake2b()),
        shareReplay(1)
      )
    ),
    map(hasher => hasher.finalize())
  );

// ä½¿ç”¨ä¾‹: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ä»˜ããƒãƒƒã‚·ãƒ¥
const progressiveHash$ = hashStream$(file$).pipe(
  scan((acc, chunk) => ({
    progress: acc.progress + chunk.length,
    hash: chunk.hash
  }), { progress: 0, hash: null })
);
```

**åˆ©ç‚¹**ï¼š
- **ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–**: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã«å¿œã˜ãŸè‡ªå‹•æ›´æ–°
- **èƒŒåœ§åˆ¶å¾¡**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è‡ªå‹•èª¿æ•´
- **åˆæˆå¯èƒ½**: è¤‡æ•°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çµ„ã¿åˆã‚ã›
- **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–**: UIã®å¿œç­”æ€§ç¶­æŒ

### **4. Capability-Based Security Model**

```rust
// ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«
use sealed::Sealed;

pub trait HashCapability: Sealed {}
pub struct Cryptographic;
pub struct FastChecksum;
pub struct PasswordHashing;

impl Sealed for Cryptographic {}
impl HashCapability for Cryptographic {}

// å‹ã‚·ã‚¹ãƒ†ãƒ ã§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿è¨¼
pub fn verify_password<C: HashCapability>(
    _capability: C,
    password: &str,
    hash: &str
) -> Result<bool, AuthError>
where
    C: From<PasswordHashing>  // ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å°‚ç”¨capabilityå¿…é ˆ
{
    // å®Ÿè£…: å‹ã‚·ã‚¹ãƒ†ãƒ ã§ä¸é©åˆ‡ãªä½¿ç”¨ã‚’é˜²æ­¢
    Argon2::verify(password, hash)
}

// ä½¿ç”¨ä¾‹
let crypto_cap = acquire_crypto_capability()?;
verify_password(crypto_cap.into(), password, stored_hash)?;
```

**åˆ©ç‚¹**ï¼š
- **æœ€å°æ¨©é™åŸå‰‡**: å¿…è¦æœ€å°é™ã®capabilityã®ã¿ä»˜ä¸
- **å‹ãƒ¬ãƒ™ãƒ«èªè¨¼**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«æ¨©é™ãƒã‚§ãƒƒã‚¯
- **ç›£æŸ»å¯èƒ½æ€§**: capabilityä½¿ç”¨ãŒæ˜ç¤ºçš„
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: ä¸æ­£ä½¿ç”¨ã®é˜²æ­¢

## ğŸ’¡ ç¾ä»£çš„çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### **ãƒ¢ãƒŠãƒ‡ã‚£ãƒƒã‚¯ Hash Pipeline**

```haskell
-- Haskellçš„ãªåˆæˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
data HashM a = HashM {
  runHash :: IO (Either HashError a)
}

instance Functor HashM where
  fmap f (HashM m) = HashM $ fmap (fmap f) m

instance Applicative HashM where
  pure = HashM . pure . Right
  (HashM f) <*> (HashM x) = HashM $ 
    liftA2 (<*>) f x

instance Monad HashM where
  (HashM m) >>= f = HashM $ do
    result <- m
    case result of
      Left err -> pure $ Left err
      Right a -> runHash $ f a

-- ä½¿ç”¨ä¾‹: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒè‡ªå‹•
hashPipeline :: ByteString -> HashM Digest
hashPipeline input = do
  validated <- validateInput input
  algorithm <- selectOptimalAlgorithm validated
  chunks <- chunkData validated
  results <- parallelHash algorithm chunks
  combineResults results
```

### **Effect System with Algebraic Data Types**

```rust
// Effect systemã«ã‚ˆã‚‹å‰¯ä½œç”¨åˆ¶å¾¡
use effect_system::{Effect, IO, Error};

#[derive(Effect)]
enum HashEffect {
    #[io] ReadFile(PathBuf) -> Result<Bytes, IoError>,
    #[cpu] ComputeHash(Bytes, Algorithm) -> Hash,
    #[log] LogProgress(u64, u64) -> (),
    #[error] HandleError(HashError) -> Never,
}

// Effect handlerã§å‰¯ä½œç”¨ã‚’åˆ¶å¾¡
async fn hash_file_with_effects<E>(
    path: PathBuf
) -> impl Effect<HashEffect, Output = Hash>
where
    E: Handler<HashEffect>
{
    effect! {
        let data = perform!(ReadFile(path))?;
        let total_size = data.len();
        
        let mut hasher = Blake2b::new();
        for (i, chunk) in data.chunks(CHUNK_SIZE).enumerate() {
            hasher.update(chunk);
            perform!(LogProgress(i * CHUNK_SIZE, total_size));
        }
        
        hasher.finalize()
    }
}
```

### **Zero-Cost Abstraction with Const Generics**

```rust
// ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ç‰¹æ®ŠåŒ–ã«ã‚ˆã‚‹æœ€é©åŒ–
use const_generic_hash::{Hash, Algorithm};

trait ConstHash<const ALGO: Algorithm, const SIZE: usize> {
    fn hash(data: &[u8]) -> [u8; SIZE];
}

// å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç‰¹æ®ŠåŒ–
impl ConstHash<{Algorithm::Blake2b}, 32> for Blake2bHasher {
    fn hash(data: &[u8]) -> [u8; 32] {
        blake2b_simd::blake2b(data).as_bytes().try_into().unwrap()
    }
}

impl ConstHash<{Algorithm::XxHash}, 8> for XxHashHasher {
    fn hash(data: &[u8]) -> [u8; 8] {
        xxhash_rust::xxh64(data, 0).to_le_bytes()
    }
}

// ä½¿ç”¨å´: å®Œå…¨ã«ã‚¼ãƒ­ã‚³ã‚¹ãƒˆ
fn secure_hash<const N: usize>(data: &[u8]) -> [u8; N] 
where
    Blake2bHasher: ConstHash<{Algorithm::Blake2b}, N>
{
    Blake2bHasher::hash(data)
}
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

### **ãƒ¬ã‚¬ã‚·ãƒ¼ vs ãƒ¢ãƒ€ãƒ³**

| é …ç›® | ãƒ¬ã‚¬ã‚·ãƒ¼è¨­è¨ˆ | ãƒ¢ãƒ€ãƒ³è¨­è¨ˆ | æ”¹å–„ç‡ |
|------|-------------|-----------|--------|
| **èµ·å‹•æ™‚é–“** | 500ms (DIåˆæœŸåŒ–) | 0ms (ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚) | âˆ |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨** | 50MB (ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ) | 1MB (é–¢æ•°) | 98%æ¸› |
| **å‹å®‰å…¨æ€§** | å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ | ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ä¿è¨¼ | 100% |
| **ä¸¦è¡Œæ€§** | ã‚¹ãƒ¬ãƒƒãƒ‰ç«¶åˆ | lock-free | 10xé«˜é€Ÿ |
| **ãƒ†ã‚¹ãƒˆæ€§** | ãƒ¢ãƒƒã‚¯å¿…è¦ | ç´”ç²‹é–¢æ•° | 5xç°¡å˜ |

### **å®Ÿè¡Œæ™‚ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰**

```rust
// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ (1GB ãƒ•ã‚¡ã‚¤ãƒ«)
//
// ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
//   - Factory + Registry: 2.3s
//   - å‹•çš„ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ: +15% ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
//   - ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–: +200MB
//
// ãƒ¢ãƒ€ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
//   - ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–: 1.8s  
//   - é™çš„ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ: 0% ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
//   - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: -95% å‰Šæ¸›
```

## ğŸ”§ å…·ä½“çš„ãªç§»è¡Œæˆ¦ç•¥

### **Phase 1: å‹ã‚·ã‚¹ãƒ†ãƒ å°å…¥**

```typescript
// æ—¢å­˜APIã‚’å‹å®‰å…¨ã«ãƒ©ãƒƒãƒ—
type LegacyHasher = {
  hash(data: Buffer): Buffer;
};

type ModernHasher<A extends Algorithm> = {
  readonly algorithm: A;
  hash<D extends InputData>(data: D): Promise<OutputFor<A, D>>;
};

// æ®µéšçš„ç§»è¡Œç”¨ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼
const modernize = <A extends Algorithm>(
  legacy: LegacyHasher,
  algorithm: A
): ModernHasher<A> => ({
  algorithm,
  hash: async (data) => legacy.hash(data) as OutputFor<A, typeof data>
});
```

### **Phase 2: éåŒæœŸåŒ–**

```rust
// åŒæœŸAPIã‚’éåŒæœŸã‚¹ãƒˆãƒªãƒ¼ãƒ ã«ãƒªãƒ•ãƒˆ
use futures::stream::{Stream, StreamExt};

fn async_hash<S>(stream: S) -> impl Stream<Item = Result<Hash, Error>>
where
    S: Stream<Item = Bytes>,
{
    stream
        .scan(Blake2b::new(), |hasher, chunk| {
            hasher.update(&chunk);
            future::ready(Some(Ok(hasher.clone().finalize())))
        })
        .take_while(|result| future::ready(result.is_ok()))
}
```

### **Phase 3: ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚·ã‚¹ãƒ†ãƒ **

```haskell
-- å‰¯ä½œç”¨ã‚’æ˜ç¤ºçš„ã«ç®¡ç†
newtype HashIO a = HashIO (ReaderT Config (ExceptT HashError IO) a)

runHashIO :: Config -> HashIO a -> IO (Either HashError a)
runHashIO config (HashIO action) = runExceptT (runReaderT action config)

-- ä½¿ç”¨ä¾‹
hashWithLogging :: ByteString -> HashIO Digest
hashWithLogging input = do
  config <- ask
  liftIO $ putStrLn "Starting hash computation"
  result <- computeHash input
  liftIO $ putStrLn "Hash computation complete"
  pure result
```

## ğŸ¯ çœŸã®ãƒ¢ãƒ€ãƒ³è¨­è¨ˆæ¡ˆ

```rust
// å®Œå…¨å‹å®‰å…¨ + ã‚¼ãƒ­ã‚³ã‚¹ãƒˆ + éåŒæœŸ
use tokio_stream::{StreamExt, wrappers::ReceiverStream};

#[derive(Clone)]
pub struct HashPipeline<A, S> 
where 
    A: HashAlgorithm + Clone + Send + 'static,
    S: Stream<Item = Bytes> + Send,
{
    algorithm: A,
    source: S,
    config: PipelineConfig,
}

impl<A, S> HashPipeline<A, S> {
    pub async fn process(self) -> Result<A::Output, HashError> {
        self.source
            .chunks(self.config.chunk_size)
            .map(|chunk| {
                let algo = self.algorithm.clone();
                tokio::spawn(async move { algo.hash_chunk(chunk).await })
            })
            .buffer_unordered(num_cpus::get())
            .try_fold(A::empty_state(), |acc, result| async {
                Ok(A::combine(acc, result?))
            })
            .await
    }
}

// ä½¿ç”¨ä¾‹: å®Œå…¨ã«å‹å®‰å…¨ã§é«˜æ€§èƒ½
let pipeline = HashPipeline::new(Blake2b::new(), file_stream, config);
let digest = pipeline.process().await?;
```

## ğŸ† çµè«–

### **å¾“æ¥è¨­è¨ˆã®å•é¡Œ**
1. **Java Enterpriseè‡­**: 2000å¹´ä»£ã®é‡ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
2. **å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼**: å‹ãƒã‚§ãƒƒã‚¯ã®æ¬ å¦‚
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–**: ç„¡é§„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘
4. **ç¾ä»£æ€§ã®æ¬ å¦‚**: éåŒæœŸãƒ»ä¸¦è¡Œæ€§ã®ç„¡è¦–

### **ç¾ä»£çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å„ªä½æ€§**
1. **é–¢æ•°å‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ **: åˆæˆå¯èƒ½ã§äºˆæ¸¬å¯èƒ½
2. **å‹å®‰å…¨æ€§**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã‚¨ãƒ©ãƒ¼æ¤œå‡º
3. **ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–**: å®Ÿè¡Œæ™‚ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã—
4. **éåŒæœŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: ç¾ä»£çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### **ç§»è¡Œã®å¿…è¦æ€§**
ç¾åœ¨ã®è¨­è¨ˆã¯**å®Œå…¨ã«ãƒ¬ã‚¬ã‚·ãƒ¼**ã€‚ã‚¯ãƒ©ã‚¹ãƒ™ãƒ¼ã‚¹ã®é‡ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ç¾ä»£ã§ã¯é€šç”¨ã—ãªã„ã€‚é–¢æ•°å‹ã€å‹å®‰å…¨æ€§ã€éåŒæœŸã€ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã¸ã®**å…¨é¢çš„ãªå†è¨­è¨ˆ**ãŒå¿…è¦ã€‚

---

**åˆ†æè€…**: Modern Architecture Critic  
**åˆ†ææ—¥**: 2025-08-28  
**å¯¾è±¡**: Hash Algorithm Packaging Patterns  
**è©•ä¾¡**: **Legacy (è¦å…¨é¢æ”¹ä¿®)**