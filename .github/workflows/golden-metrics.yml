# Golden Metrics Regression Guard
# Automated performance regression detection for StrataRegula

name: Golden Metrics Guard

on:
  pull_request:
    branches: [ main, master, develop ]
    paths:
      - 'strataregula/**'
      - 'tests/**'
      - 'scripts/**'
      - 'pyproject.toml'
      - 'requirements.txt'
  
  push:
    branches: [ main, master ]
    paths:
      - 'strataregula/**'
      - 'tests/golden/**'

  workflow_dispatch:
    inputs:
      strictness:
        description: 'Test strictness level'
        required: false
        default: 'normal'
        type: choice
        options:
          - normal
          - strict
          - ci

jobs:
  golden-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    strategy:
      matrix:
        python-version: ['3.11']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need history for baseline comparison

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements.txt
          pip install -e ".[test]"  # Install test dependencies including pytest
          pip install -e ".[dev]"   # Install development dependencies
          pip install psutil  # Required for memory measurement
          
          # Ensure all required packages are available
          python -c "
          import strataregula
          import psutil
          print('âœ… All dependencies installed successfully')
          print(f'StrataRegula version: {strataregula.__version__}')
          print(f'psutil version: {psutil.__version__}')
          "

      - name: Verify golden baseline exists
        run: |
          if [ ! -f "tests/golden/baseline/metrics.json" ]; then
            echo "âŒ Golden baseline not found!"
            echo "Run 'make golden-baseline' locally and commit the baseline files"
            exit 1
          fi
          echo "âœ… Golden baseline found"
          cat tests/golden/baseline/metrics.json
          
      - name: Create reports directory
        run: |
          mkdir -p reports/junit

      - name: Run Golden Metrics Guard (Normal)
        if: github.event.inputs.strictness == 'normal' || github.event.inputs.strictness == ''
        env:
          GOLDEN_LATENCY_ALLOW_PCT: '1.0'
          GOLDEN_P95_ALLOW_PCT: '1.2'
          GOLDEN_THROUGHPUT_ALLOW_PCT: '0.5'
          GOLDEN_MEMORY_ALLOW_PCT: '2.0'
          GOLDEN_CACHE_ALLOW_PCT: '1.0'
        run: |
          echo "ðŸŽ¯ Running Golden Metrics Guard (Normal strictness)"
          pytest -v tests/golden/test_regression_guard.py \
            --junitxml=reports/junit/golden-results.xml

      - name: Run Golden Metrics Guard (CI - Relaxed)
        if: github.event.inputs.strictness == 'ci'
        env:
          GOLDEN_LATENCY_ALLOW_PCT: '1.5'
          GOLDEN_P95_ALLOW_PCT: '2.0'
          GOLDEN_THROUGHPUT_ALLOW_PCT: '1.0'
          GOLDEN_MEMORY_ALLOW_PCT: '3.0'
          GOLDEN_CACHE_ALLOW_PCT: '1.5'
        run: |
          echo "ðŸ¤– Running Golden Metrics Guard (CI relaxed thresholds)"
          pytest -v tests/golden/test_regression_guard.py \
            --junitxml=reports/junit/golden-results.xml

      - name: Run Golden Metrics Guard (Strict)
        if: github.event.inputs.strictness == 'strict'
        env:
          GOLDEN_LATENCY_ALLOW_PCT: '0.5'
          GOLDEN_P95_ALLOW_PCT: '0.8' 
          GOLDEN_THROUGHPUT_ALLOW_PCT: '0.2'
          GOLDEN_MEMORY_ALLOW_PCT: '1.0'
          GOLDEN_CACHE_ALLOW_PCT: '0.5'
        run: |
          echo "ðŸŽ¯ Running Golden Metrics Guard (Strict - Production ready)"
          pytest -v tests/golden/test_regression_guard.py \
            --junitxml=reports/junit/golden-results.xml

      - name: Upload golden metrics reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: golden-metrics-reports-${{ matrix.python-version }}
          path: |
            reports/current/**
            reports/diff/**
            reports/junit/**
          retention-days: 30

      - name: Comment on PR with results
        if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == false && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = 'reports/diff';
            
            if (fs.existsSync(path)) {
              const files = fs.readdirSync(path).filter(f => f.endsWith('.md'));
              if (files.length > 0) {
                const reportFile = files[0];
                const report = fs.readFileSync(`${path}/${reportFile}`, 'utf8');
                
                github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: `## ðŸ“Š Golden Metrics Report\n\n${report}\n\n---\n*Generated by Golden Metrics Guard*`
                });
              }
            }

      - name: Fail if regressions detected
        if: failure()
        run: |
          echo "âŒ Performance regressions detected!"
          echo "ðŸ“Š Check the uploaded artifacts for detailed reports"
          echo "ðŸ”§ Review recent changes that may impact performance"
          exit 1

  baseline-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check if baseline was modified
        id: baseline-check
        run: |
          if git diff --name-only origin/${{ github.base_ref }}...HEAD | grep -q "tests/golden/baseline/"; then
            echo "baseline_modified=true" >> $GITHUB_OUTPUT
            echo "âš ï¸ Golden baseline files have been modified in this PR"
          else
            echo "baseline_modified=false" >> $GITHUB_OUTPUT
          fi

      - name: Comment on baseline changes
        if: steps.baseline-check.outputs.baseline_modified == 'true' && github.event.pull_request.head.repo.fork == false
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## âš ï¸ Golden Baseline Modified
              
              This PR modifies the golden metrics baseline files. Please verify:
              
              - [ ] Baseline changes are intentional (performance improvement or architecture change)
              - [ ] New baseline values are reasonable and expected
              - [ ] All regression tests pass with new baseline
              
              **Modified files:**
              \`\`\`
              ${context.payload.pull_request.changed_files?.filter(f => f.includes('tests/golden/baseline/')).join('\n') || 'tests/golden/baseline/'}
              \`\`\`
              
              *Baseline changes require careful review to ensure we don't mask performance regressions.*`
            });
